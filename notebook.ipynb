"""
Colab Whisper Transcriber
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. è«‹ä¾ç…§ä¸‹æ–¹åˆ‡åˆ†ä¹‹æ®µè½ï¼Œåœ¨ colab ç·¨è­¯å™¨ä¸Šé¢åˆ†æ®µè½è²¼ä¸Šã€‚
2. ç¬¬1æ­¥é©Ÿ~ç¬¬3æ­¥é©Ÿç‚º dependency çš„å®‰è£ **ï¼ˆåƒ…ç¬¬ä¸€æ¬¡åŸ·è¡Œéœ€è¦ï¼‰** ï¼Œæ¥ä¸‹ä¾†è½‰éŒ„é€å­—ç¨¿åªéœ€è¦åŸ·è¡Œç¬¬4æ­¥é©Ÿ **ä¸»æµç¨‹** å³å¯ã€‚
2. å°‡éŸ³æª”æ‹–åˆ° Colab å·¦å´ Files æˆ–ç”¨ upload è¦–çª—ä¸Šå‚³
3. è‡ªå‹•è½‰æˆ 16 kHz / mono WAV âœ Whisper (zh-TW) âœ .txt
Author: Hsiu-Chi Tsaiï¼ˆè”¡ç§€å‰ï¼‰
"""

# â”€â”€ 1. å®‰è£ç³»çµ±èˆ‡ Python å¥—ä»¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
!apt-get -y update && apt-get -y install -y ffmpeg
!pip install --quiet --upgrade openai-whisper pydub opencc-python-reimplemented

# â”€â”€ 2. åŒ¯å…¥æ‰€éœ€å‡½å¼åº« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
import tempfile
import torch
from typing import Optional

from google.colab import files
from pydub import AudioSegment
import whisper
from opencc import OpenCC

# â”€â”€ 3. å·¥å…·å‡½å¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def convert_to_wav(src_path: str, target_sr: int = 16_000) -> str:
    """
    å°‡ä»»ä½•æ ¼å¼éŸ³æª”è½‰æˆ 16 kHzãƒ»monoãƒ»16-bit PCM WAVã€‚
    å›å‚³æš«å­˜æª”è·¯å¾‘ï¼Œè™•ç†éå¾Œè‡ªå‹•åˆªé™¤åŸæª”ä¸æœƒå½±éŸ¿ã€‚
    """
    audio = AudioSegment.from_file(src_path)
    audio = (
        audio.set_frame_rate(target_sr)
             .set_channels(1)
             .set_sample_width(2)        # 16-bit
    )
    wav_path = tempfile.mktemp(suffix=".wav")
    audio.export(wav_path, format="wav")
    return wav_path


def transcribe_zh_tw(wav_path: str, model_size: str = "medium") -> str:
    """
    ä½¿ç”¨ Whisper è½‰éŒ„ + OpenCC ç°¡â†’ç¹ã€‚
    model_size å¯é¸ tiny/base/small/medium/largeã€‚
    """
    print(f"â³ Loading Whisper {model_size} model â€¦")
    model = whisper.load_model(model_size)
    print("ğŸ”Š Transcribing â€¦ï¼Œç­‰å°±å°äº†")
    result = model.transcribe(
        wav_path,
        language="zh",
        fp16=torch.cuda.is_available()
    )
    # Whisper å¯èƒ½å¤¾é›œç°¡é«”ï¼Œå¾Œè™•ç†è½‰ç¹é«”
    cc = OpenCC("s2t")
    return cc.convert(result["text"])


def save_transcript(text: str, src_filename: str) -> str:
    """
    ä»¥ä¾†æºæª”åç‚ºåŸºç¤ï¼Œå„²å­˜ *_transcript.txtï¼Œä¸¦å›å‚³æª”åã€‚
    """
    stem = os.path.splitext(os.path.basename(src_filename))[0]
    txt_path = f"{stem}_transcript.txt"
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(text)
    return txt_path


# â”€â”€ 4. ä¸»æµç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main(src_path: Optional[str] = None, model_size: str = "medium") -> None:
    """
    å¦‚æœ src_path ç‚º Noneï¼Œå‰‡å•Ÿå‹• files.upload() è®“ä½¿ç”¨è€…æŒ‘æª”ï¼›
    å¦å‰‡ç›´æ¥ä½¿ç”¨æŒ‡å®šæª”æ¡ˆã€‚
    """
    # 4-1 é¸å–éŸ³æª”
    if src_path is None:
        uploads = files.upload()
        if not uploads:
            raise RuntimeError("æ²’æœ‰æª”æ¡ˆï¼è«‹è‡³å°‘ä¸Šå‚³ä¸€å€‹éŸ³æª”ã€‚")
        src_path = next(iter(uploads))
    if not os.path.exists(src_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{src_path}")

    print(f"\nğŸ“¥ Source file: {src_path}")

    # 4-2 è½‰æˆ WAV
    wav_path = convert_to_wav(src_path)
    print(f"ğŸ§ Converted to WAV: {wav_path}")

    # 4-3 Whisper è½‰éŒ„
    transcript = transcribe_zh_tw(wav_path, model_size=model_size)

    # 4-4 å„²å­˜ãƒ»ä¸‹è¼‰
    txt_path = save_transcript(transcript, src_path)
    print("\n==== è½‰éŒ„çµæœï¼ˆç¹é«”ï¼‰ ====\n")
    print(transcript)
    print(f"\nğŸ’¾ Saved transcript â†’ {txt_path}")
    files.download(txt_path)


# â”€â”€ 5. åŸ·è¡Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è‹¥æƒ³æ‰‹å‹•æŒ‡å®šç›®éŒ„ä¸‹çš„æª”æ¡ˆï¼Œå¯æŠŠ src_path æ”¹æˆå¯¦éš›è·¯å¾‘ï¼›
# ç•™ç©ºä»£è¡¨è·³å‡ºä¸Šå‚³è¦–çª—ã€‚
main(src_path=None, model_size="medium")
